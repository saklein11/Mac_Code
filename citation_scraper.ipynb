{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in PMID csv file created through\n",
    "path = \"/Users/manatee_prime/Desktop/NCA/\"\n",
    "\n",
    "citation = [[],[],[]]\n",
    "scrape = [[],[]]\n",
    "\n",
    "f = open(path + 'NCA_citations.csv','r')\n",
    "for line in f:\n",
    "    if line.split('|')[0] != 'NCA':\n",
    "        citation[0].append(line.split('|')[0])\n",
    "        citation[1].append(line.split('|')[1])\n",
    "        citation[2].append(line.split('|')[2])\n",
    "        scrape[0].append(line.split('|')[3])\n",
    "        scrape[1].append(line.split('|')[4].rstrip())\n",
    "\n",
    "print(len(citation[0]),len(citation[1]),len(citation[2]),len(scrape[0]),len(scrape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: need way to handle and remove the \"page X of \\n Y\" from the documents as it can ruin a good citation\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "path = \"/Users/manatee_prime/Desktop/NCA/\"\n",
    "\n",
    "###Create list of only txt files for reading###\n",
    "dir_nca = os.listdir(path) #get all file names on path\n",
    "\n",
    "dir_nca_txt = [] #create new list to hold only the .txt files\n",
    "for item in dir_nca: \n",
    "    if \".txt\" in item: #include only txt files\n",
    "        dir_nca_txt.append(item)\n",
    "#dir_nca = dir_nca[1:10]\n",
    "\n",
    "###Global variables for containing ALL NCA info###\n",
    "citation = [[],[],[]] #0 = memo indicating origin doc, #1 = date, #2 = citation\n",
    "for nca in dir_nca_txt:\n",
    "    f = open(path + nca,'r')\n",
    "    memo = False\n",
    "    date = False\n",
    "    bib = False\n",
    "    tmpbuff = []\n",
    "    for line in f: \n",
    "        ###Grab document topic for later comparison###\n",
    "        if memo == False and line != \"\\n\":\n",
    "            tmpbuff.append(line.rstrip())\n",
    "        if memo == False and line == \"\\n\":\n",
    "            memo = \" \".join(tmpbuff) #memo will be used to code the citation below\n",
    "        \n",
    "        ###Grab date information###\n",
    "        if line.split(\" \")[0] == 'Date:' or line.split(\" \")[0] == 'DATE:':\n",
    "            if date == False: \n",
    "                date = True\n",
    "                continue\n",
    "            \n",
    "        if date == True and line != '\\n':\n",
    "            tmpdate = line.replace(\" \",\"\").rstrip()\n",
    "            if len(tmpdate.split(\",\")[0]) > 4:\n",
    "                try:\n",
    "                    date = datetime.strptime(tmpdate, '%B%d,%Y')\n",
    "                except ValueError:\n",
    "                    print(\"DATETIME FAULT!\",nca,'  ',date)\n",
    "                    break\n",
    "            if len(tmpdate.split(\",\")[0]) == 4:\n",
    "                try:\n",
    "                    date = datetime.strptime(tmpdate, '%b%d,%Y')\n",
    "                except ValueError:\n",
    "                    print(\"DATETIME FAULT! \",tmpdate,'\\t',nca)\n",
    "                    break\n",
    "        \n",
    "        ###Grab author information###\n",
    "        #Could update to include CCSQ author information\n",
    "        \n",
    "        ###Grab bibliometric information###\n",
    "        if bib == True:\n",
    "            if line != \"\\n\" and line.split(\" \")[0] != \"Created\":\n",
    "                if \"\\x0c\" in line:\n",
    "                    tmpbuff.append(line.split(\"\\x0c\")[1].rstrip())\n",
    "                else:\n",
    "                    tmpbuff.append(line.rstrip())\n",
    "            if line == \"\\n\" and len(tmpbuff) > 0:\n",
    "                citation[0].append(memo) #code citation with origin document\n",
    "                if date == False or date == True:\n",
    "                    print(\"BOOLEAN FAULT! \",nca,'  ',date)\n",
    "                citation[1].append(date) #code citation with date of citing document\n",
    "                \n",
    "                tmpbuff = \" \".join(tmpbuff)\n",
    "                citation[2].append(tmpbuff) #append citation to final list\n",
    "                tmpbuff = []\n",
    "        if line == \"Bibliography\\n\":\n",
    "            bib = True\n",
    "    f.close()\n",
    "    \n",
    "print(len(citation[0]),len(citation[1]),len(citation[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell creates a stopwords set for comparison to putative title sections\n",
    "#Additional terms have been added to the stopwords dictionary to try and capture common science terms\n",
    "#NOTE: It would be interesting to look for a library of the most common words in science!\n",
    "\n",
    "#Run this cell once to get the stop variable necessary to get pmids\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "###Set up stopwords for evaluating title strings###\n",
    "stop = set(stopwords.words('english'))\n",
    "b = set([])\n",
    "for x in ['test','tests','tested','testing','study','studies','studied','studying','clinic','clinical','review',\n",
    "          'investigation','investigate','investigating','investigated','patient','patients','measure','measured',\n",
    "          'measuring','treatment','treat','treating','treats','treated','therapy','therapies','therapeutic',\n",
    "         'effect','effects','effected','effecting','disease','condition']:\n",
    "    stop.add(x) #add the above terms to the stop list\n",
    "for x in stop:\n",
    "    if len(x) < 2:\n",
    "        b.add(x) #make new set of all elements in stop that are 1 letter long\n",
    "stop -= b #remove intersection of stop and b from stop (ie stop = stop - b)\n",
    "\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block converts the free text citations into PMIDs where possible\n",
    "#NOTE: This script modifies the citation list made above so will need to rerun that script BEFORE rerun this one\n",
    "#This version uses titles as they are the easiest to identify but using the journal/vol/pages could be better\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#Create function to find similarity\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "#tester = citation[2][0:50]\n",
    "\n",
    "scrape = [[],[]] #0 = pmid #,'broken','url',etc. #1 = simscore value\n",
    "ct = 0 #used to keep track of iteration number\n",
    "ct2 = 0\n",
    "\n",
    "for i in range(len(citation[2])):\n",
    "#for i in range(2000):\n",
    "    ct += 1\n",
    "    if ct % 300 == 0:\n",
    "        print(ct,' completed of ',len(citation[2]))\n",
    "    title = \"\"\n",
    "    jrndat = \"\" #currently not in use but could use #letters/#words with re.sub to id the journal,vol,page info\n",
    "    separator = \".\"\n",
    "    found = False\n",
    "\n",
    "    ######PARSING PMIDS FROM CITATIONS W PMIDS######\n",
    "    if 'PMID' in citation[2][i]:\n",
    "        junk = re.sub('[^0-9]','',citation[2][i].split('PMID')[1])\n",
    "        ###Manually identified corrections###\n",
    "        #Note - PMIDs have max 8 digits and most have 8, making that assumption is generally ok\n",
    "        if junk == '233864216': #correction\n",
    "            junk = '23864216'\n",
    "        if 'A-Derogatis LR, Lipman RS, Rickels K, Uhlenhuth EH, Covi L' in citation[2][i]:\n",
    "            junk = '4808738'\n",
    "        if 'Hoenig J, Kenna JC, Youd A. Surgical treatment for transsexualism' in citation[2][i]:\n",
    "            junk = '5096332'\n",
    "        if 'Hoenig J, Kenna J. Epidemiological aspects of transsexualism' in citation[2][i]:\n",
    "            junk = '4705331'\n",
    "        if 'Juckett, G. Cross-Cultural Medicine. Am Fam Physician.' in citation[2][i]:\n",
    "            junk = '16342851'\n",
    "        if junk == '283545633':\n",
    "            junk = '28545633'\n",
    "        if junk == '162665560':\n",
    "            junk = '16266560'\n",
    "        if junk == '855872510':\n",
    "            junk = '8558725'\n",
    "        if 'Nguyen N and Holodniy M.  HIV infection in the elderly' in junk:\n",
    "            junk = '18982916'\n",
    "        ###Parse PMIDS###\n",
    "        if len(junk) > 8:\n",
    "            junk = junk[0:8]\n",
    "        scrape[0].append(junk)\n",
    "        scrape[1].append('NA')\n",
    "        continue\n",
    "    ######END BLOCK######\n",
    "    \n",
    "    ######PARSING CITATIONS######\n",
    "    ###Remove urls from citation pool###\n",
    "    if 'http://' in citation[2][i] or 'https://' in citation[2][i] or 'www.' in citation[2][i]: #ignore all the website data\n",
    "        scrape[0].append('url')\n",
    "        scrape[1].append('NA')\n",
    "        continue\n",
    "    \n",
    "    ###Look for citations with quotes###\n",
    "    if citation[2][i].count('\\'') != 2 and citation[2][i].count('\\'') != 0: #Here to catch crazy weird citations\n",
    "        scrape[0].append('q broken')\n",
    "        scrape[1].append('NA')\n",
    "        continue\n",
    "    if citation[2][i].count('\\'') == 2: \n",
    "        if citation[2][i].split('\\'')[1].count(' ') > 2:\n",
    "            separator = '\\''\n",
    "\n",
    "    ###Look for title, journal/date using separator###\n",
    "    tmpq = citation[2][i].lower().replace('et al','').split(separator) #think about using the et al as a split!\n",
    "        \n",
    "    #Find the title using length and stopwords\n",
    "    title = [re.sub('[^A-z]',' ',x) for x in tmpq] #get rid of numbers to ensure length best measure\n",
    "    test = [1,0,0] #0 = index in title, 1 = number of words (split on ' '), 2 = # stop words\n",
    "    \n",
    "    for x in range(len(title)):\n",
    "        comp = list(filter(None,title[x].split(' '))) #create list and remove empties from it\n",
    "        complst = [x, len(comp), len(stop & set(comp))]\n",
    "        if complst[1] + 5*complst[2] > test[1] + 5*test[2]: #this weighting gave optimal # results\n",
    "            test = complst\n",
    "    if test == [1,0,0] or len(tmpq[test[0]].split(' ')) < 3:\n",
    "        scrape[0].append('broken')\n",
    "        scrape[1].append('NA')\n",
    "        continue\n",
    "    \n",
    "    title = tmpq[test[0]] #set title to the best term in the original tmpq list\n",
    "    title = re.sub('[^A-z|0-9|\\s|\\:|\\-|,|;]','',title)\n",
    "    \n",
    "    ###Search for PMID using EUtils and query###\n",
    "    skey = 'dcff69acdc62008c90b1354b0ac141dc0808' #api key to get more queries to ncbi eutils\n",
    "    tmpmid = []\n",
    "    \n",
    "    #Search for PMID\n",
    "    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={0}&api_key={1}'.format(title,skey)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser') #try and run xml.parser to see if it has one\n",
    "    content = soup.find_all('id')\n",
    "    if content == None:\n",
    "        scrape[0].append('broken')\n",
    "        scrape[1].append('NA')\n",
    "        continue\n",
    "    if content != None:\n",
    "        tmpmid = [str(x).split('>')[1].split('<')[0] for x in content]\n",
    "    if len(tmpmid) > 5:\n",
    "        tmpmid = tmpmid[0:5]\n",
    "        ct2 += 1\n",
    "    \n",
    "    #Check if PMID correct\n",
    "    for putative in tmpmid:\n",
    "        time.sleep(0.1)\n",
    "        tstitle = ''\n",
    "        url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&id={0}&api_key={1}'.format(putative,skey) #fetch summary for dbck\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        \n",
    "        content = str(soup.find('item', attrs={'name':\"Title\"})).split('>')[1].split('<')[0]\n",
    "        tstitle = re.sub('[^A-z|0-9|\\s|:|\\-|,|;]','',content).lower()\n",
    "        pages = str(soup.find('item',attrs={'name':\"Pages\"})).split('>')[1].split('<')[0]\n",
    "        vol = str(soup.find('item',attrs={'name':\"Volume\"})).split('>')[1].split('<')[0]\n",
    "        if pages == '':\n",
    "            pages = '{FAKE!}'\n",
    "        if vol == '':\n",
    "            vol = '{FAKE!}'\n",
    "        \n",
    "        #Commented out: jaccard distance using n-grams\n",
    "        #n1 = set(nltk.ngrams(tstitle,n=5))\n",
    "        #n2 = set(nltk.ngrams(title,n=5)) \n",
    "        #if 1 - nltk.jaccard_distance(n1,n2) > 0.8:\n",
    "        if similar(tstitle,title) > 0.9: #the false positive rate here is negligible so take anything that hits\n",
    "            scrape[0].append(putative)\n",
    "            #scrape[0].append(content) #false positive chk\n",
    "            scrape[1].append(similar(tstitle,title))\n",
    "            found = True\n",
    "            break\n",
    "        #Commented out: jaccard distance using n-grams\n",
    "        #if 1 - nltk.jaccard_distance(n1,n2) > 0.5 and pages in citation[2][i] and vol in citation[2][i]:\n",
    "        if similar(tstitle,title) > 0.5 and pages in citation[2][i] and vol in citation[2][i]: #o-cutoff = 0.667\n",
    "            scrape[0].append(putative)\n",
    "            #scrape[0].append(content) #false positive chk\n",
    "            scrape[1].append(similar(tstitle,title))\n",
    "            found = True\n",
    "            break    \n",
    "    \n",
    "    #If everything failed, keep tack of citation anyways\n",
    "    if found == False:\n",
    "        scrape[0].append('failed')\n",
    "        scrape[1].append('NA')\n",
    "    ######END BLOCK######\n",
    "        \n",
    "print(len(scrape[0]),len(scrape[1]),scrape[0].count('failed') + scrape[0].count('broken') +\n",
    "      scrape[0].count('q broken') + scrape[0].count('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######SCRATCH FOR WORKING WITH PMID FINDING CODE######\n",
    "'''\n",
    "s1 = 'Embolism treated with mitral clip and cardiac stents in situ'\n",
    "s2 = 'Embolism treated with mitral clip and cardiac stents in place'\n",
    "w1 = set(s1)\n",
    "w2 = set(s2)\n",
    "n1 = set(nltk.ngrams(s1,n=3))\n",
    "n2 = set(nltk.ngrams(s2,n=3))\n",
    "\n",
    "print(similar(s1,s2),1 - nltk.jaccard_distance(w1,w2),1 - nltk.jaccard_distance(n1,n2),\n",
    "      1 - nltk.edit_distance(s1,s2)/max(len(s1),len(s2)))'''\n",
    "\n",
    "for i in range(len(scrape[0])):\n",
    "    if scrape[1][i] != 'NA':\n",
    "        if 0.8 < scrape[1][i] < 0.95:\n",
    "        #if 0.95 < scrape[1][i]:\n",
    "            print(citation[2][i]+'\\n',scrape[0][i]+'\\n',scrape[1][i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple evaluation stats for testing false positives\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "\n",
    "print('Total number of PMIDS: ',len(hdat),'\\n',\n",
    "      'Unique PMIDs: ', len(collections.Counter(hdat)))\n",
    "\n",
    "ct = 0 \n",
    "hdat = []\n",
    "for dat in scrape[1]:\n",
    "    if dat != 'NA':\n",
    "        ct += 1\n",
    "        hdat.append(float(dat)) #float needed when importing scrape[1] data from file\n",
    "\n",
    "plt.hist(hdat,50)\n",
    "plt.xlim(0.5,1.0)\n",
    "plt.ylim(0,100)\n",
    "\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######WRITE OUT NCA_citations.csv FILE FOR R ANALYSIS######\n",
    "\n",
    "import csv\n",
    "\n",
    "#Be sure to remove delimiter from ALL indexes in the citation list!\n",
    "for i in range(len(citation[2])):\n",
    "    if '|' in citation[2][i]:\n",
    "        citation[2][i] = citation[2][i].replace('|','')\n",
    "        print(citation[2][i])\n",
    "\n",
    "with open(path + 'NCA_citations.csv', 'w', encoding = 'utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='|')\n",
    "    writer.writerow(['NCA','Date','Text','Citation','Similarity'])\n",
    "    for i in range(len(citation[0])):\n",
    "        writer.writerow([citation[0][i],citation[1][i],citation[2][i],scrape[0][i],scrape[1][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######BEGINNING GRANT ANALYSIS CODE######\n",
    "\n",
    "\n",
    "#This code returns grant information on all pmids gathered from pubmed\n",
    "import collections\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "#NOTE: consider adding article date information to grant scraper for accurate dating down to the day\n",
    "#      use 'pubdate' to grab date information for future grant searches\n",
    "grant = [[],[],[],\n",
    "         [],[],[],[]] #0=originator CMS doc, 1=free txt citation, 2=citation PMID, 3=grant number, 4=grant agency, 5=country\n",
    "ct = 0\n",
    "\n",
    "pmidlist = collections.Counter(scrape[0])\n",
    "\n",
    "for pmid in range(len(scrape[0])):\n",
    "    #Counter to track number of citations tackled\n",
    "    ct += 1\n",
    "    if ct % 300 == 0:\n",
    "        print(pmid/len(citation[2]),' completed!')\n",
    "    \n",
    "    try:\n",
    "        int(scrape[0][pmid]) #Test if PMID as all PMIDs are integers\n",
    "        \n",
    "        skey = 'dcff69acdc62008c90b1354b0ac141dc0808' #api key to get more queries to ncbi eutils\n",
    "        time.sleep(0.2) #setting to 0.1 throws over-query error\n",
    "        url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={0}&retmode=xml&api_key={1}\".format(scrape[0][pmid],skey)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        \n",
    "        ###SCRAPE PUBLICATION DATE INFORMATION###\n",
    "        date = soup.find_all('pubdate')\n",
    "        pubdate = ''\n",
    "        for item in date:\n",
    "            for subitem in item: #pubdate lists in order: year, month, day\n",
    "                if 'year' in str(subitem):\n",
    "                    pubdate = str(subitem).split('>')[1].split('<')[0]\n",
    "                if 'month' in str(subitem):\n",
    "                    pubdate = pubdate + '-' + str(subitem).split('>')[1].split('<')[0]\n",
    "                if 'day' in str(subitem):\n",
    "                    pubdate = pubdate + '-' + str(subitem).split('>')[1].split('<')[0]\n",
    "            if a.count('-') == 1:\n",
    "                pubdate = pubdate + '-15' #arbitrarily set Y-M dates to Y-M-15 (middle of month)\n",
    "        grant[6].append(pubdate)\n",
    "        ###END BLOCK###\n",
    "        \n",
    "        ###SCRAPE GRANT INFORMATION###\n",
    "        content = soup.find_all('grant')\n",
    "        if content == None:\n",
    "            grant[0].append(citation[0][pmid])\n",
    "            grant[1].append(citation[2][pmid])\n",
    "            grant[2].append(scrape[0][pmid])\n",
    "            grant[3].append('NA')\n",
    "            grant[4].append('NA')\n",
    "            grant[5].append('NA')\n",
    "            continue\n",
    "\n",
    "        for item in content:\n",
    "            gid = False\n",
    "            agency = False\n",
    "            country = False\n",
    "            grant[0].append(citation[0][pmid])\n",
    "            grant[1].append(citation[2][pmid])\n",
    "            grant[2].append(scrape[0][pmid])\n",
    "            \n",
    "            for j in item:\n",
    "                if 'grantid' in str(j):\n",
    "                    grant[3].append(str(j).split('>')[1].split('<')[0])\n",
    "                    gid = True\n",
    "                    continue\n",
    "                if 'agency' in str(j):\n",
    "                    grant[4].append(str(j).split('>')[1].split('<')[0])\n",
    "                    agency = True\n",
    "                    continue\n",
    "                if 'country' in str(j):\n",
    "                    grant[5].append(str(j).split('>')[1].split('<')[0])\n",
    "                    country = True\n",
    "                    continue\n",
    "            \n",
    "            if gid == False:\n",
    "                grant[3].append('NA')\n",
    "            if agency == False:\n",
    "                grant[4].append('NA')\n",
    "            if country == False:\n",
    "                grant[5].append('NA')\n",
    "        ###END BLOCK###\n",
    "                \n",
    "    except ValueError: #Pass by non-PMID entries\n",
    "        #grant[0].append('NA')\n",
    "        #grant[1].append('NA')\n",
    "        #grant[2].append('NA')\n",
    "        continue\n",
    "\n",
    "print(len(grant[0]),len(grant[1]),len(grant[2]),len(grant[3]),len(grant[4]),len(grant[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple evaluation stats for grant data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "\n",
    "agencies = collections.Counter(grant[4])\n",
    "pmids = collections.Counter(grant[2])\n",
    "dat = []\n",
    "for x in pmids:\n",
    "    dat.append(pmids[x])\n",
    "    if dat[-1] > 10:\n",
    "        print(x,'\\t',pmids[x])\n",
    "\n",
    "print(agencies)\n",
    "    \n",
    "plt.hist(dat,50)\n",
    "#plt.xlim(0,90)\n",
    "#plt.ylim(0,10)\n",
    "\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct known synonyms for grant agencies\n",
    "nodes = [x for x in collections.Counter(grant[4])]\n",
    "for item in nodes:\n",
    "    print(item)\n",
    "'''\n",
    "syns = ['Canadian Institutes of Health Research', 'Canadian Institute of Health Research', 'CIHR']\n",
    "\n",
    "for i in range(len(grant[4])):\n",
    "    if grant[4][i] in syns:\n",
    "        grant[4][i] = 'Canadian Institutes of Health Research'\n",
    "        print('corrected!')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create nodes and edges file for visNetwork in R\n",
    "#Nodes file == list of all possible nodes\n",
    "#Edges file == [[from],[to],[weight]], for this analysis weight == 1 unless to CMS, then it == counts\n",
    "#NOTE - Have not removed redundant citations. This COULD provide a basic weighting that would be useful\n",
    "#       BUT it would probably over-weight citations from similar/multi-stage NCAs\n",
    "\n",
    "import collections\n",
    "\n",
    "pmids = collections.Counter(grant[2])\n",
    "tmpl2 = [] #this will house all the combinations of grants\n",
    "#edges = [[],[],[]] #0 = origin node, 1 = destination node, 2 = edge weight\n",
    "\n",
    "for pmid in pmids:\n",
    "    tmpl = [] #re-create tmp list for each iteration\n",
    "    \n",
    "    #assemble all grants for a particular pmid in tmpl\n",
    "    for i in range(len(grant[2])):\n",
    "        if grant[2][i] == pmid and grant[4][i] != 'NA':\n",
    "            tmpl.append(grant[4][i])\n",
    "            \n",
    "    if len(tmpl) == 0: #move on from missing grant data\n",
    "        continue\n",
    "    if len(tmpl) == 1: #ensure singletons still count towards CMS\n",
    "        tmpl2.append(tmpl[0]+'_CMS')\n",
    "        continue\n",
    "        \n",
    "    #join all grants funding same publication\n",
    "    tmpl = sorted(tmpl) #arrange alphabetically to impose standard order\n",
    "    for j in range(len(tmpl)):\n",
    "        tmpl2.append(tmpl[j]+'_CMS') #each grant in tmpl[0] connects to CMS\n",
    "        for k in range(j+1,len(tmpl)):\n",
    "            tmpl2.append(tmpl[j]+'_'+tmpl[k]) #each grant within a pub should connect to eachother\n",
    "\n",
    "edgect = collections.Counter(tmpl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "path = \"/Users/manatee_prime/Desktop/NCA/\"\n",
    "\n",
    "#write out raw grant info file\n",
    "with open(path + 'NCA_grants.csv', 'w', encoding = 'utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='|')\n",
    "    writer.writerow(['NCA','Text','PMID','Grant Number','Grant Agency','Agency Country']) #set up to match visNetwork syntax\n",
    "    for i in range(len(grant[0])):\n",
    "        writer.writerow([grant[0][i],grant[1][i],grant[2][i],grant[3][i],grant[4][i],grant[5][i]])\n",
    "csvfile.close()\n",
    "\n",
    "#write out edges file\n",
    "with open(path + 'NCA_grantagency_ntwk_edges.csv', 'w', encoding = 'utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='|')\n",
    "    writer.writerow(['from','to','value']) #set up to match visNetwork syntax\n",
    "    for item in edgect:\n",
    "        writer.writerow([item.split('_')[0],item.split('_')[1],edgect[item]])\n",
    "csvfile.close()\n",
    "\n",
    "#write out nodes file\n",
    "nodes = [x for x in collections.Counter(grant[4])]\n",
    "with open(path + 'NCA_grantagency_ntwk_nodes.csv', 'w', encoding = 'utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='|')\n",
    "    writer.writerow(['id']) #set up to match visNetwork syntax\n",
    "    writer.writerow(['CMS']) #add cms to the nodes network\n",
    "    for item in nodes:\n",
    "        writer.writerow([item])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Term Follow-Up After \n",
      "\n",
      "Administration of Human Gene \n",
      "\n",
      "Therapy Products \n",
      "\n",
      "\n",
      "\n",
      "Guidance for Industry \n",
      "\n",
      "\n",
      "\n",
      "Additional copies of this guidance are available from the Office of Communication, Outreach \n",
      "\n",
      "and Development (OCOD), 10903 New Hampshire Ave., Bldg. 71, Rm. 3128, Silver Spring, \n",
      "\n",
      "MD 20993-0002, or by calling 1-800-835-4709 or 240-402-8010, or email ocod@fda.hhs.gov, or \n",
      "\n",
      "from the Internet at https://www.fda.gov/vaccines-blood-biologics/guidance-compliance-\n",
      "\n",
      "regulatory-information-biologics/biologics-guidances. \n",
      "\n",
      "\n",
      "\n",
      "For questions on the content of this guidance, contact OCOD at the phone numbers or email \n",
      "\n",
      "address listed above. \n",
      "\n",
      "\n",
      "\n",
      "U.S. Department of Health and Human Services \n",
      "\n",
      "Food and Drug Administration \n",
      "\n",
      "Center for Biologics Evaluation and Research \n",
      "\n",
      "January 2020 \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "Contains Nonbinding Recommendations \n",
      "\n",
      "\n",
      "\n",
      "Table of Contents \n",
      "\n",
      "\n",
      "\n",
      "IV. \n",
      "\n",
      "\n",
      "\n",
      "V. \n",
      "\n",
      "\n",
      "\n",
      "C. \n",
      "\n",
      "\n",
      "\n",
      "D. \n",
      "\n",
      "\n",
      "\n",
      "B. \n",
      "\n",
      "C. \n",
      "\n",
      "\n",
      "\n",
      "I. \n",
      "\n",
      "II. \n",
      "\n",
      "III. \n",
      "\n",
      "\n",
      "\n",
      "INTRODUCTION............................................................................................................. 1 \n",
      "\n",
      "SCOPE ............................................................................................................................... 2 \n",
      "\n",
      "BACKGROUND ............................................................................................................... 2 \n",
      "\n",
      "A. \n",
      "\n",
      "Potential Risks of Delayed Adverse Events Following Exposure to Human \n",
      "\n",
      "Gene Therapy Products ........................................................................................ 2 \n",
      "\n",
      "History .................................................................................................................... 3 \n",
      "\n",
      "Experience Gained Through Long Term Follow-up of Subjects in Gene \n",
      "\n",
      "Therapy Trials ....................................................................................................... 4 \n",
      "\n",
      "D. \n",
      "\n",
      "Long Term Follow-up for Novel Gene Therapy Products ................................ 5 \n",
      "\n",
      "PRECLINICAL DATA USED FOR ASSESSMENT OF DELAYED RISKS IN \n",
      "\n",
      "GENE THERAPY CLINICAL TRIALS ........................................................................ 5 \n",
      "\n",
      "A. \n",
      "\n",
      "Criteria to Assess Potential Delayed Risks of Gene Therapy Products ........... 5 \n",
      "\n",
      "B. \n",
      "\n",
      "Considerations for Preclinical Study Design to Assess Biodistribution and \n",
      "\n",
      "Persistence of Gene Therapy Product ................................................................. 9 \n",
      "\n",
      "Vector Persistence, Integration, and Reactivation and Genome Modification: \n",
      "\n",
      "Assessing Long Term Risks................................................................................ 11 \n",
      "\n",
      "Considerations for Preclinical Evaluation of Products that Involve Genome \n",
      "\n",
      "Editing .................................................................................................................. 15 \n",
      "\n",
      "RECOMMENDATIONS FOR PROTOCOLS FOR LONG TERM FOLLOW-UP \n",
      "\n",
      "OBSERVATIONS: CLINICAL CONSIDERATIONS ............................................... 15 \n",
      "\n",
      "A. \n",
      "\n",
      "Goals of the Long Term Follow-up Observations ............................................ 15 \n",
      "\n",
      "B. \n",
      "\n",
      "Clinical Trial Populations for Long Term Follow-up Observations .............. 16 \n",
      "\n",
      "C. \n",
      "\n",
      "Duration of Long Term Follow-up Observations ............................................ 16 \n",
      "\n",
      "D. \n",
      "\n",
      "Elements of Long Term Follow-up Observations ............................................ 17 \n",
      "\n",
      "E. \n",
      "\n",
      "Informed Consent in Trials Involving Long Term Follow-up Observations 21 \n",
      "\n",
      "F. \n",
      "\n",
      "Special Considerations Regarding Integrating Vectors .................................. 22 \n",
      "\n",
      "G. \n",
      "\n",
      "Special Considerations Regarding Product Involving Genome Editing ........ 26 \n",
      "\n",
      "VI. GENERAL CONSIDERATIONS FOR POST-MARKETING MONITORING \n",
      "\n",
      "PLANS FOR GENE THERAPY PRODUCTS ............................................................ 26 \n",
      "\n",
      "VII. LONG TERM FOLLOW-UP UNDER SPECIAL CIRCUMSTANCES .................. 27 \n",
      "\n",
      "VIII. DEFINITIONS ................................................................................................................ 28 \n",
      "\n",
      "IX. REFERENCES ................................................................................................................ 30 \n",
      "\n",
      "APPENDICES ............................................................................................................................. 33 \n",
      "\n",
      "\n",
      "\n",
      "i \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\f",
      "Contains Nonbinding Recommendations \n",
      "\n",
      "\n",
      "\n",
      "Long Term Follow-Up After Administration of Human Gene \n",
      "\n",
      "Therapy Products  \n",
      "\n",
      "\n",
      "\n",
      "Guidance for Industry \n",
      "\n",
      "\n",
      "\n",
      "This guidance represents the current thinking of the Food and Drug Administration (FDA or \n",
      "\n",
      "Agency) on this topic.  It does not establish any rights for any person and is not binding on FDA \n",
      "\n",
      "or the public.  You can use an alternative approach if it satisfies the requirements of the \n",
      "\n",
      "applicable statutes and regulations.  To discuss an alternative approach, contact the FDA staff \n",
      "\n",
      "responsible for this guidance as listed on the title page. \n",
      "\n",
      "\n",
      "\n",
      "I. \n",
      "\n",
      "\n",
      "\n",
      "INTRODUCTION \n",
      "\n",
      "\n",
      "\n",
      "We, FDA, are providing you, a sponsor who is developing a human gene therapy product (GT \n",
      "\n",
      "Product), 1 recommendations regarding the design of long term follow-up studies (LTFU \n",
      "\n",
      "observations) for the collection of data on delayed adverse events following administration of a \n",
      "\n",
      "GT product.  Often, GT products are designed to achieve therapeutic effect through permanent or \n",
      "\n",
      "long-acting changes in the human body.  As a result of long term exposure to an investigational \n",
      "\n",
      "GT product, study subjects may be at increased risk of undesirable and unpredictable outcomes \n",
      "\n",
      "that may present as delayed adverse event(s).  To understand and mitigate the risk of a delayed \n",
      "\n",
      "adverse event, subjects in gene therapy trials may be monitored for an extended period of time, \n",
      "\n",
      "which is commonly referred to as the “long term follow-up” (LTFU) period (of a clinical study).  \n",
      "\n",
      "LTFU observations are extended assessments that continue some of the scheduled observations \n",
      "\n",
      "of a clinical trial past the active follow-up period, and are an integral portion of the study of \n",
      "\n",
      "some investigational GT products.  LTFU observations are important to monitor long term safety \n",
      "\n",
      "of GT products.  For GT products that present long term risks to subjects, LTFU/surveillance \n",
      "\n",
      "plan(s) should also be put in place post-licensure for monitoring of delayed adverse events (for \n",
      "\n",
      "details we refer you to section VI. of this document).  Not all GT products will require LTFU \n",
      "\n",
      "observations; a risk assessment should be performed by a sponsor based on several factors as \n",
      "\n",
      "outlined in this guidance.  \n",
      "\n",
      "\n",
      "\n",
      "In this guidance, we provide a brief introduction of the product characteristics, patient-related \n",
      "\n",
      "factors, and the preclinical and clinical data that should be considered when assessing the need \n",
      "\n",
      "for LTFU observations for your GT product.  We also provide recommendations for the study \n",
      "\n",
      "design of LTFU observations, with specific considerations for different GT products and \n",
      "\n",
      "recommendations on patient monitoring for licensed GT products.  Definitions of terms used \n",
      "\n",
      "throughout this guidance are provided in section VIII. of this document.  \n",
      "\n",
      "\n",
      "\n",
      "This guidance finalizes the draft guidance of the same title dated July 2018 and supersedes the \n",
      "\n",
      "document entitled “Guidance for Industry:  Gene Therapy Clinical Trials – Observing Subjects \n",
      "\n",
      "\n",
      "\n",
      "1 See section VIII. Definitions:  Human gene therapy product.  \n",
      "\n",
      "\n",
      "\n",
      "1 \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "                                                 \n",
      "\n",
      "\f",
      "Contains Nonbinding Recommendations \n",
      "\n",
      "\n",
      "\n",
      "for Delayed Adverse Events” dated November 2006 (Ref. 1) (2006 Delayed Adverse Events).  \n",
      "\n",
      "This guidance is also intended to supplement the guidance entitled “Testing of Retroviral Vector-\n",
      "\n",
      "Based Human Gene Therapy Products for Replication Competent Retrovirus during Product \n",
      "\n",
      "Manufacture and Patient Follow-up; Guidance for Industry” dated January 2020. 2 \n",
      "\n",
      "\n",
      "\n",
      "FDA’s guidance documents, including this guidance, do not establish legally enforceable \n",
      "\n",
      "responsibilities.  Instead, guidances describe the FDA’s current thinking on a topic and should be \n",
      "\n",
      "viewed only as recommendations, unless specific regulatory or statutory requirements are cited. \n",
      "\n",
      "The use of the word should in FDA’s guidances means that something is suggested or \n",
      "\n",
      "recommended, but not required.  \n",
      "\n",
      "\n",
      "\n",
      "II. \n",
      "\n",
      "\n",
      "\n",
      "SCOPE \n",
      "\n",
      "\n",
      "\n",
      "This guidance applies to all gene therapy clinical studies and to licensed GT products for which \n",
      "\n",
      "LTFU observations are warranted based on analyses of available preclinical and clinical safety \n",
      "\n",
      "data for the GT product that raises concerns for delayed adverse events.  The recommendations \n",
      "\n",
      "in this guidance apply to human GT products that produce long lasting genetic effects and the \n",
      "\n",
      "performance of LTFU observations for evidence of delayed adverse events, i.e., adverse events \n",
      "\n",
      "that occur past the active follow-up period after exposure to the GT product, as described in the \n",
      "\n",
      "main study protocol. 3 \n",
      "\n",
      "\n",
      "\n",
      "III. BACKGROUND \n",
      "\n",
      "\n",
      "\n",
      "A. \n",
      "\n",
      "\n",
      "\n",
      "Potential Risks of Delayed Adverse Events Following Exposure to Human \n",
      "\n",
      "Gene Therapy Products  \n",
      "\n",
      "\n",
      "\n",
      "Characteristics unique to human GT products that may be associated with delayed \n",
      "\n",
      "adverse events include: \n",
      "\n",
      "\n",
      "\n",
      "1. \n",
      "\n",
      "\n",
      "\n",
      "The integration activity of the GT product:  The biological activity of \n",
      "\n",
      "retroviral vectors 4 (e.g., vectors derived from gammaretrovirus, lentivirus, \n",
      "\n",
      "foamy virus etc.) and transposon elements is imparted by an integration \n",
      "\n",
      "event in the genome.  In general, such integration is not directed to \n",
      "\n",
      "specific sites in the human genome, and this raises the potential for \n",
      "\n",
      "disruption of critical host (human) genes at the site of integration, or \n",
      "\n",
      "activation of proto-oncogenes near the integration site(s) and, thereby, the \n",
      "\n",
      "risk for malignancies. \n",
      "\n",
      "\n",
      "\n",
      "2 “Testing of Retroviral Vector- Based Human Gene Therapy Products for Replication Competent Retrovirus during \n",
      "\n",
      "Product Manufacture and Patient Follow-up; Guidance for Industry” is available at this website: \n",
      "\n",
      "https://www.fda.gov/media/113790/download.  \n",
      "\n",
      "3 This guidance does not apply to vaccines for infectious disease indications, bacteriophage products, live \n",
      "\n",
      "biotherapeutic products, fecal microbiota for transplantation (FMT) products and allergenic products.    \n",
      "\n",
      "4 See section VIII. Definitions:  Vector. \n",
      "\n",
      "\n",
      "\n",
      "2 \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "  \n",
      "\n",
      "                                                 \n",
      "\n",
      "\f",
      "2. \n",
      "\n",
      "\n",
      "\n",
      "3. \n",
      "\n",
      "\n",
      "\n",
      "4. \n",
      "\n",
      "\n",
      "\n",
      "5. \n",
      "\n",
      "\n",
      "\n",
      "Contains Nonbinding Recommendations \n",
      "\n",
      "\n",
      "\n",
      "Genome editing activity:  Genome editing-based GT products impart their \n",
      "\n",
      "biological activity through site-specific changes in the human genome, but \n",
      "\n",
      "may also have off-target effects on the genome (Ref. 2).  Similar to \n",
      "\n",
      "integrating vectors, genome editing may produce undesirable changes in \n",
      "\n",
      "the genome (whether ex vivo or in vivo), with the risk of malignancies, \n",
      "\n",
      "impairment of gene function, etc. \n",
      "\n",
      "\n",
      "\n",
      "Prolonged expression:  A GT product where the transgene (therapeutic \n",
      "\n",
      "gene) encodes growth factors, such as vascular endothelial growth factor \n",
      "\n",
      "(VEGF) or proteins associated with cell division such as p53, may raise \n",
      "\n",
      "the potential for unregulated cell growth and malignancies due to \n",
      "\n",
      "prolonged exposure to the therapeutic protein.  Similarly, transgenes \n",
      "\n",
      "encoding immune recognition factors may introduce the risk for \n",
      "\n",
      "autoimmune-like reactions (to self-antigens) upon prolonged exposure.  \n",
      "\n",
      "For GT products that carry transcriptional regulatory elements (e.g., \n",
      "\n",
      "microRNA) or immune-modulatory proteins (e.g., cytokines) there is also \n",
      "\n",
      "the risk of unknown pleotropic effects, including altered expression of \n",
      "\n",
      "host (human) genes that could result in unpredictable and undesirable \n",
      "\n",
      "outcomes.  \n",
      "\n",
      "\n",
      "\n",
      "Latency:  When the GT product has the potential for latency, such as a \n",
      "\n",
      "herpesvirus, there is the potential for reactivation from latency and the risk \n",
      "\n",
      "of delayed adverse events related to a symptomatic infection. \n",
      "\n",
      "\n",
      "\n",
      "Establishment of persistent infections:  GT products that are  replication \n",
      "\n",
      "competent viruses and bacteria, such as listeria-based bacterial vectors, \n",
      "\n",
      "have the potential to establish persistent infections in \n",
      "\n",
      "immunocompromised patients leading to the risk of developing a delayed \n",
      "\n",
      "but serious infection.   \n",
      "\n",
      "\n",
      "\n",
      "In addition to product-related factors, the long term risk profile of a GT product should \n",
      "\n",
      "also take into consideration the target cell/tissues/organ, and the patient population (age, \n",
      "\n",
      "immune status, risk of mortality etc.), and the relevant disease characteristics.   \n",
      "\n",
      "\n",
      "\n",
      "B. \n",
      "\n",
      "\n",
      "\n",
      "History  \n",
      "\n",
      "\n",
      "\n",
      "The recommendations for LTFU monitoring in the 2006 Delayed Adverse Events \n",
      "\n",
      "guidance (Ref. 1) were based on extensive discussions among gene therapy stakeholders, \n",
      "\n",
      "and cumulative preclinical and clinical experience with GT products (Refs. 3, 4, 5) as \n",
      "\n",
      "summarized in this section.  To discuss and solicit advice about long term risks to \n",
      "\n",
      "subjects exposed to such products, three separate meetings of the FDA advisory \n",
      "\n",
      "committee, Biological Response Modifiers Advisory Committee (BRMAC), were \n",
      "\n",
      "convened on November 17, 2000, April 6, 2001, and October 24, 2001 (Ref. 6).   \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "path = \"/Users/manatee_prime/Desktop/\"\n",
    "i = 0\n",
    "\n",
    "f = open(path + 'fda_test.txt','r')\n",
    "for line in f:\n",
    "    i += 1\n",
    "    if i < 300:\n",
    "        print(line)\n",
    "    if i > 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
